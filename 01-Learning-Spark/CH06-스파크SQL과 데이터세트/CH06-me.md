# 6. 스파크 SQL과 데이터 세트

# 1. 자바와 스칼라를 위한 단일 API

- 스파크 지원 언어 중 스칼라와 자바만 강력하게 형식화된 타입으로 지정
- 파이썬과 R은 형식화되지 않은 타입의 데이터 프레임 API 지원

## 1.1 데이터 세트를 위한 스칼라 케이스 클래스와 자바빈

- 데이터세트: 데이터 프레임 API에서 익숙하게 사용되는 DSL 연산자나 함수형 프로그래밍을 사용하여 병렬로 작동할 수 있는 도메인별 형식화된 객체
- 스파크는 StringType, BinaryType, IntegerType, BooleanType 및 MapType같은 내부적 데이터 타입을 가지고 있으며 스칼라 및 자바의 언어별 데이터 타입에 원할하게 매핑하는 데 사용되며 이 매핑은 인코더를 통해 수행
- Dataset[T]를 생성하기 위해, 여기서 T는 스칼라에서 형식화된 객체이기 때문에 객체를 정의하는 case class가 필요
- 스칼라 및 자바에서 데이터세트를 만들때 각 행에 대한 모든 개별 컬럼 이름과 유형을 알아야 함
- 스파크가 스키마를 유추하도록 할 수 있는 데이터 프레임과 달리 데이터세트 API에서는 미리 데이터 유형을 정의하고, 케이스 클래스 또는 자바빈 클래스가 스키마와 일치해야 함
- 스칼라 케이스 클래스 또는 자바 클래스 정의의 필드 이름은 데이터 원본의 순서와 일치해야 함
- 자바에서는 명시적 인코드를 사용하지만 스칼라에서 스파크는 암시적으로 처리

# 2. 데이터세트 작업

## 2.1. Dataset 생성 및 데이터 구성

- **객체 기반 생성**: `SparkSession`을 통해 특정 도메인 객체(Scala Case Class, Java 필드)를 기반으로 생성함
- **언어별 차이**: Scala는 인코더를 암시적(Implicit)으로 처리하나, Java는 `Encoders.bean()`을 통해 명시적으로 인코더를 정의해야 함
- **강력한 타입 체크**: 생성 시점에 데이터 타입을 확정하여 컴파일 단계에서 오류를 검출할 수 있는 안전성을 제공함

## 2.2. 고차 함수(Higher-order Functions)를 이용한 변환

- **함수형 프로그래밍 적용**: `filter()`, `map()` 등의 함수에 람다(Lambda)나 익명 함수를 인자로 전달하여 병렬 처리를 수행함
- **객체 접근 방식**: 객체지향 프로그래밍의 '점 표기법(Dot notation)'을 사용하여 각 필드에 직접 접근하므로 코드 가독성이 높음
- **유연한 결과 반환**: 조건에 따른 불리언(Boolean) 판별뿐만 아니라, `map()`을 통해 기존 데이터를 가공하여 새로운 타입의 객체(예: `UsageCost`)로 변환 가능함

## 2.3. DataFrame과 Dataset의 상호 운용

- **상호 변환**: DataFrame은 `as[T]` 메서드를 사용하여 특정 타입의 Dataset으로 변환할 수 있음
- **구조적 관계**: DataFrame은 사실상 `Dataset[Row]`이며, Row라는 범용적이고 타입이 지정되지 않은 객체를 다루는 특수한 형태의 Dataset임
- **선택적 사용**: 복잡한 비즈니스 로직에는 타입 안전성이 있는 Dataset을 사용하고, 단순 연산에는 최적화에 유리한 DSL/SQL 방식을 혼용할 수 있음

## 추가 정보: 실무적 관점의 보충 설명

### 람다 vs DSL 선택 기준

- **람다(함수형)**: 복잡한 조건문(`if-else`)이나 외부 라이브러리 함수를 호출해야 하는 가독성 위주의 작업에 적합함
- **DSL(표현식)**: 성능이 중요한 대규모 데이터 처리 시, 역직렬화 오버헤드를 줄이기 위해 `$"column" > 900`과 같은 표현식 사용을 권장함

### 직렬화와 타입 안전성(Type-safety)

- **컴파일 타임 에러**: Dataset은 존재하지 않는 필드를 참조할 경우 실행 전 컴파일 단계에서 에러를 잡아내어 런타임 안정성을 보장함
- **성능 트레이드오프**: 타입 안전성을 얻는 대신, 이진 데이터를 JVM 객체로 변환하는 과정에서 발생하는 CPU 자원 소모를 고려해야 함

# 3. 데이터세트 및 데이터 프레임을 위한 메모리 관리

## 3.1 왜 메모리 관리가 중요한가?

- Spark는 **In-Memory** 연산
- 엔진초기에는 데이터를 JVM 힙(Heap) 메모리에 Java 객체 형태로 저장했는데 이 방식은 두 가지 큰 문제를 일으킴
    - **Garbage Collection(GC) 부하**: 데이터가 많아지면 GC가 실행되는 동안 Spark의 동작이 멈추는 'Stop-the-world' 현상이 잦았습니다.
    - **메모리 오버헤드**: 단순한 문자열 하나를 저장하더라도 Java 객체 자체의 메타데이터 때문에 실제 데이터보다 훨씬 큰 메모리를 사용했습니다.

## 3.2 스파크 버전별 메모리 관리 진화사

### 3.2.1. 초기 Spark (1.0 - 1.5 미만): 정적 메모리 관리 시대

- **Static Memory Manager 구조**: 사용자가 설정한 비율에 따라 저장용(Storage)과 실행용(Execution) 메모리 영역을 엄격히 분리하여 운영
- **자원 낭비 발생**: 한쪽 영역의 메모리가 충분히 남더라도 다른 영역에서 이를 빌려 쓸 수 없는 구조적 한계 노출
- **JVM 의존성**: 모든 데이터를 Java 객체 형태로 힙(Heap) 메모리에 저장하여 과도한 가비지 컬렉션(GC) 부하 유발

### 3.2.2. Spark 1.5: 프로젝트 텅스텐(Project Tungsten) 혁신

- **Off-Heap 메모리 관리**: JVM 관리 영역 밖의 메모리를 직접 제어하여 GC의 간섭을 최소화하고 안정성 확보
- **바이너리 데이터 포맷**: Java 객체의 오버헤드를 제거하기 위해 데이터를 직렬화된 이진 형태로 저장하여 메모리 사용량 절감
- **L1/L2 캐시 최적화**: 데이터 구조를 CPU 캐시 친화적으로 설계하여 데이터 조회 및 연산 속도 극대화

### 3. Spark 1.6 - 2.x: 통합 메모리 관리 시대

- **Unified Memory Manager 도입**: 저장용과 실행용 메모리의 경계를 허물고 필요에 따라 유연하게 공유하는 방식 채택
- **동적 점유 방식**: 실행 메모리가 부족할 경우 저장 메모리 영역을 강제로 비우고(Eviction) 자원을 점유하는 우선순위 체계 확립
- **Dataset API의 통합**: Catalyst 최적화 엔진을 통해 쿼리 실행 계획을 메모리 효율적으로 자동 변환

### 4. Spark 3.0 - 현재: 지능형 및 적응형 관리 시대

- **AQE(Adaptive Query Execution)**: 실행 중 수집된 통계를 바탕으로 런타임에 파티션 크기를 조정하여 메모리 불균형(Skew) 해소
- **DPP(Dynamic Partition Pruning)**: 불필요한 데이터를 메모리에 로드하기 전 단계에서 차단하여 전체적인 메모리 점유율 최적화
- **가속화 지원**: 대규모 워크로드를 위해 GPU 메모리와의 연동을 강화하고 가상화된 환경에서의 메모리 효율성 개선

# 4. 데이터 집합 인코더

## 4.1. 인코더(Encoder)의 정의 및 역할

- **데이터 변환 주체**: Spark 내부의 **Tungsten 이진 포맷**과 **JVM 객체** 사이의 상호 변환을 수행하는 구성 요소
- **직렬화 및 역직렬화**: 데이터를 네트워크로 전송하거나 메모리에 저장하기 위해 이진 형태로 인코딩하고, 분석을 위해 다시 객체로 디코딩함
- **자동 생성 지원**: 기본 데이터 타입(String, Int 등), Scala Case Class, JavaBeans에 대해 Spark가 효율적인 바이트코드를 자동으로 생성함
- **성능 우위**: 기존 Java나 Kryo 직렬화 방식에 비해 처리 속도가 현저히 빠름

## 4.2. Tungsten 포맷과 메모리 효율성

- **메모리 오버헤드 제거**: Java 객체의 헤더, 해시코드, 유니코드 정보 등 부가적인 데이터 점유 공간을 최소화함
- **오프힙(Off-heap) 관리**: JVM 힙 메모리 외부의 연속된 메모리 공간에 데이터를 배치하여 가비지 컬렉션(GC)의 간섭을 피함
- **직접 접근 방식**: 메모리 주소와 오프셋을 이용한 **포인터 연산**으로 데이터에 즉각 접근하여 연산 속도를 극대화함

## 4.3. 성능 최적화 전략 및 주의사항

- **람다(Lambda) 사용의 비용**: `filter(x => ...)`와 같은 익명 함수 사용 시, 이진 데이터를 JVM 객체로 변환하는 역직렬화 비용이 매번 발생함
- **Catalyst 최적화 한계**: 람다 내부 로직은 Spark의 최적화 엔진인 Catalyst가 분석할 수 없어 실행 계획 최적화가 불가능함
- **DSL 활용**: `$"column"` 형태의 Spark 전용 표현식을 사용하면 객체 변환 없이 이진 상태 그대로 연산이 가능하여 성능이 향상됨

## 추가 정보: Dataset 성능을 좌우하는 보충 개념

### Catalyst 옵티마이저와의 관계

- **논리적 계획 최적화**: 사용자가 DSL을 사용할 경우 Catalyst가 쿼리 전체를 분석하여 불필요한 컬럼 제거(Projection Pushdown)나 필터 최적화(Predicate Pushdown)를 수행함
- **코드 생성(Whole-Stage Code Generation)**: 여러 연산 단계를 하나의 최적화된 Java 함수로 합쳐 실행 속도를 높이는 기술로, 인코더와 함께 작동하여 성능을 극대화함
